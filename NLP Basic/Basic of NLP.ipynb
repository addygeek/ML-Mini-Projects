{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\adity\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\adity\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\adity\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\adity\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK provides powerful tools for tokenzation. It is easy to use NLTK in Python. NLTK makes text processing simple.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#sample text \n",
    "txt = \"NLTK provides powerful tools for tokenzation. It is easy to use NLTK in Python. NLTK makes text processing simple.\"\n",
    "print(txt)\n",
    "print(type(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'provides',\n",
       " 'powerful',\n",
       " 'tools',\n",
       " 'for',\n",
       " 'tokenzation',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'use',\n",
       " 'NLTK',\n",
       " 'in',\n",
       " 'Python',\n",
       " '.',\n",
       " 'NLTK',\n",
       " 'makes',\n",
       " 'text',\n",
       " 'processing',\n",
       " 'simple',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boy is good, Girl is good, both Boys and Girls are good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Boy',\n",
       " 'is',\n",
       " 'good',\n",
       " ',',\n",
       " 'Girl',\n",
       " 'is',\n",
       " 'good',\n",
       " ',',\n",
       " 'both',\n",
       " 'Boys',\n",
       " 'and',\n",
       " 'Girls',\n",
       " 'are',\n",
       " 'good']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2 = \"Boy is good, Girl is good, both Boys and Girls are good\"\n",
    "print(txt2)\n",
    "#word tokenization \n",
    "word_tokenize(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boy is good, Girl is good, both Boys and Girls are good']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentence tokenization\n",
    "sent_tokenize(txt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop words: words that are filtered out before or after processing of text\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'sample', 'sentence', 'to', 'demonstrate', 'stop', 'words', ',', 'i', 'am', 'you']\n"
     ]
    }
   ],
   "source": [
    "#tokenization of whole sentenecs\n",
    "sen = \"This is sample sentence to demonstrate stop words, I am You\"\n",
    "sen =sen.lower()\n",
    "wod = word_tokenize(sen)\n",
    "print(wod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'sentence', 'demonstrate', 'stop', 'words', ',']\n"
     ]
    }
   ],
   "source": [
    "#lets filter stopwords\n",
    "new_sen = [word for word in wod if word not in stopwords.words('english')]\n",
    "print(new_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization are text preprocessing techniques used in Natural Language Processing (NLP) to reduce words to their base or root form. They help improve text normalization, making it easier for machines to analyze text data.\n",
    "\n",
    "Stemming is the process of reducing a word to its root form by removing suffixes. However, it does not always produce a meaningful word, as it follows rule-based chopping without considering the actual meaning. \n",
    "\n",
    "Running\t>    Run,\n",
    "Happily>\tHappi,\n",
    "Studies\t>   Studi\n",
    "\n",
    "Lemmatization reduces a word to its dictionary root form (lemma) while ensuring that the root word is a valid word in the language.\n",
    "\n",
    "Running\t> Run,\n",
    "Studies\t> Study,\n",
    "Caring\t>Care,\n",
    "Better\t> Good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming: process of reducing inflected words to their word stem, base or root form\n",
    "# stemming is used to reduce the words to their root form\n",
    "# eg. running -> run, eating -> eat, happening -> happen, happiness -> happy (but happi is not a word)\n",
    "#lemmatization: process of reducing words to their base or root form\n",
    "# lemmatization is used to reduce the words to their root form\n",
    "\n",
    "# difference between stemming and lemmatization\n",
    "# stemming is faster than lemmatization\n",
    "# stemming is less accurate than lemmatization\n",
    "# stemming is used to reduce the words to their root form\n",
    "# lemmatization is used to reduce the words to their base form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
